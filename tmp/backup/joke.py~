import requests
import pymysql
from lxml import etree

db = pymysql.connect(host = '127.0.0.1',port=3306,user='root',password='903108759',database="mydb")

cursor = db.cursor()

headers = {'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36'}

base_page_url = 'https://xiaohua.zol.com.cn/new/'

domain = 'https://xiaohua.zol.com.cn/' 

# 这是一个简单的爬虫
def parse_page(page_url):
    resp=requests.get(page_url,headers=headers)
    text=resp.text
    parser=etree.HTML(text)
    detail_urls=parser.xpath("//ul[@class='article-list']/li[@class='article-summary']/div[@data-id]/a[@class='all-read']/@href")
    for detail in detail_urls:
        detail_url=domain+detail
        parse_detail(detail_url)

def parse_detail(detail_url):
    detail_resp=requests.get(detail_url,headers=headers)
    detail_text=detail_resp.text
    detail_parser=etree.HTML(detail_text)
    title=detail_parser.xpath("//div[@class='wrapper clearfix']//div[@class='section article']/div[@class='article-header']//h1[@class='article-title']/text()")[0]
    contents=detail_parser.xpath("//div[@class='wrapper clearfix']//div[@class='section article']/div[@class='article-text']//text()")
    print(title)
    content=''
    for i in contents:
        content+=i.strip()
    sql = "insert into myjock3(id,title,content)values(null,%s,%s)"
    cursor.execute(sql,(title,content))
    

def main():
    for page in range(1,40):
        page_url= base_page_url+str(page)+'.html'
        parse_page(page_url)
        

if __name__ == "__main__":
    main()
    db.commit()
    db.close()

